{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def extract_combined_features(image):\n",
    "    # Extract all features\n",
    "    color_features = extract_color_features(image)\n",
    "    lbp_features = extract_lbp_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "    \n",
    "    # Combine all features\n",
    "    combined_features = np.concatenate([color_features, lbp_features, hog_features])\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "def extract_color_features(img):\n",
    "    # Convert to different color spaces\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    # Compute color histograms\n",
    "    hist_rgb = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist_hsv = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    hist_lab = cv2.calcHist([lab], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # Flatten and normalize histograms\n",
    "    hist_rgb = hist_rgb.flatten() / hist_rgb.sum()\n",
    "    hist_hsv = hist_hsv.flatten() / hist_hsv.sum()\n",
    "    hist_lab = hist_lab.flatten() / hist_lab.sum()\n",
    "    \n",
    "    # Compute mean and std for each channel\n",
    "    means_rgb = img.mean(axis=(0, 1))\n",
    "    stds_rgb = img.std(axis=(0, 1))\n",
    "    \n",
    "    return np.concatenate([hist_rgb, hist_hsv, hist_lab, means_rgb, stds_rgb])\n",
    "\n",
    "def extract_lbp_features(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Set LBP parameters\n",
    "    radius = 3  # Radius of the circle\n",
    "    n_points = 8 * radius  # Number of points to consider in the LBP calculation\n",
    "    \n",
    "    # Compute the LBP representation of the image\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute the histogram of the LBP\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)  # Avoid division by zero\n",
    "    \n",
    "    return hist\n",
    "\n",
    "def extract_hog_features(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), orientations=9):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = hog(gray, orientations=orientations, pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block, block_norm='L2-Hys', feature_vector=True)\n",
    "    return features\n",
    "\n",
    "def extract_sift_features(image, num_features=100):\n",
    "    sift = cv2.SIFT_create(nfeatures=num_features)\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros((num_features, 128))  # SIFT descriptor is 128-dimensional\n",
    "    if descriptors.shape[0] < num_features:\n",
    "        padding = np.zeros((num_features - descriptors.shape[0], 128))\n",
    "        descriptors = np.vstack((descriptors, padding))\n",
    "    return descriptors[:num_features].flatten()\n",
    "\n",
    "def extract_surf_features(image, num_features=100, hessian_threshold=400):\n",
    "    surf = cv2.xfeatures2d.SURF_create(hessianThreshold=hessian_threshold, nOctaves=4, nOctaveLayers=3, extended=False, upright=True)\n",
    "    keypoints, descriptors = surf.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros((num_features, 64))  # SURF descriptor is 64-dimensional\n",
    "    if descriptors.shape[0] < num_features:\n",
    "        padding = np.zeros((num_features - descriptors.shape[0], 64))\n",
    "        descriptors = np.vstack((descriptors, padding))\n",
    "    return descriptors[:num_features].flatten()\n",
    "\n",
    "def extract_features(image, method):\n",
    "    # HOG\n",
    "    if method == 'HOG':\n",
    "        return extract_hog_features(image)\n",
    "    \n",
    "    # SIFT\n",
    "    if method == 'SIFT':\n",
    "        return extract_sift_features(image)\n",
    "        \n",
    "    # SURF\n",
    "    if method == 'SURF':\n",
    "        return extract_surf_features(image)\n",
    "    \n",
    "    if method == 'Combined':\n",
    "        return extract_combined_features(image)\n",
    "\n",
    "\n",
    "def create_pixel_features(image, mask, method):\n",
    "    X = extract_features(image, method)\n",
    "    y = np.apply_along_axis(lambda x: x[0], 1, mask.reshape(-1,3))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "target_size = (256, 256)\n",
    "\n",
    "# Used for training on all V datasets (K datasets are corrupted after downloading from Sharepoint)\n",
    "def get_input_output_paths(root_dir, sub_dirs, max_samples=None):\n",
    "    input_paths = []\n",
    "    target_paths = []\n",
    "    samples_per_dir = max_samples // len(sub_dirs) if max_samples else None\n",
    "    for sub_dir in sub_dirs:\n",
    "        input_dir = os.path.join(root_dir, sub_dir, 'image')\n",
    "        sub_input_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir)]\n",
    "        random.shuffle(sub_input_paths)\n",
    "        sub_target_paths = list(map(lambda x: x.replace(\"image\", \"indexLabel\"), sub_input_paths))\n",
    "        \n",
    "        if samples_per_dir:\n",
    "            sub_input_paths = sub_input_paths[:samples_per_dir]\n",
    "            sub_target_paths = sub_target_paths[:samples_per_dir]\n",
    "        \n",
    "        input_paths.extend(sub_input_paths)\n",
    "        target_paths.extend(sub_target_paths)\n",
    "    return input_paths, target_paths\n",
    "\n",
    "input_img_paths, _ = get_input_output_paths('WildScenes2d', ['V-01', 'V-02', 'V-03'], 50)\n",
    "\n",
    "def resize_image_and_mask(image, mask, target_size):\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    mask_resized = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    return image_resized, mask_resized\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "\n",
    "for img_path in input_img_paths:\n",
    "    img = np.asarray(cv2.imread(img_path))\n",
    "    mask = np.asarray(cv2.imread(img_path.replace('image', 'indexLabel')))\n",
    "    img, mask = resize_image_and_mask(img, mask, target_size)\n",
    "    img, mask = create_pixel_features(img, mask, method='Combined')\n",
    "    X_all.append(img)\n",
    "    y_all.append(mask)\n",
    "\n",
    "X = np.array(X_all)\n",
    "y = np.array(y_all)\n",
    "\n",
    "def get_majority_values(arr):\n",
    "    flat_arr = arr.flatten()\n",
    "    \n",
    "    # Get unique values and their counts\n",
    "    unique, counts = np.unique(flat_arr, return_counts=True)\n",
    "    \n",
    "    # Find the maximum count\n",
    "    max_count = counts.max()\n",
    "    \n",
    "    # Get all values with the maximum count\n",
    "    majority_values = unique[counts == max_count]\n",
    "    \n",
    "    return majority_values[0]\n",
    "\n",
    "majority_values = np.apply_along_axis(get_majority_values, 1, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "(36, 36164)\n",
      "(12, 36164)\n",
      "(36, 65536)\n",
      "(12, 65536)\n",
      "[ 8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8 17\n",
      "  8  8  8  8  8  8  8  8  8  8  8  7  8  8  8  8  8  8  8  8  8  8  8  8]\n"
     ]
    }
   ],
   "source": [
    "print(len(input_img_paths))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# print(np.unique(majority_values))\n",
    "# print(np.count(2))\n",
    "print(majority_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.0901632308959961, 3: 0.0012070337931315105, 4: 0.003926595052083333, 5: 0.001873016357421875, 7: 0.13138357798258463, 8: 0.527019182840983, 9: 0.01747290293375651, 12: 0.00017611185709635416, 14: 0.00017801920572916666, 15: 0.010582605997721354, 16: 0.0010506312052408855, 17: 0.07652568817138672, 18: 0.1384414037068685}\n",
      "{2: 0.084136962890625, 4: 0.0038121541341145835, 7: 0.1360897488064236, 8: 0.5277188618977865, 9: 0.016742282443576388, 12: 0.00019158257378472222, 14: 0.00023735894097222222, 15: 0.012568155924479166, 16: 0.0011435614691840278, 17: 0.07187186347113715, 18: 0.14548746744791666}\n",
      "{2: 0.10824203491210938, 3: 0.004828135172526042, 4: 0.004269917805989583, 5: 0.0074920654296875, 7: 0.1172650655110677, 8: 0.5249201456705729, 9: 0.019664764404296875, 12: 0.00012969970703125, 15: 0.004625956217447917, 16: 0.0007718404134114584, 17: 0.09048716227213542, 18: 0.11730321248372395}\n"
     ]
    }
   ],
   "source": [
    "def element_proportions(arr):\n",
    "    flat_arr = arr.flatten()\n",
    "    unique, counts = np.unique(flat_arr, return_counts=True)  \n",
    "    total = len(flat_arr)\n",
    "    proportions = counts / total    \n",
    "    return dict(zip(unique, proportions))\n",
    "\n",
    "print(element_proportions(y))\n",
    "print(element_proportions(y_train))\n",
    "print(element_proportions(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'max_leaf_node'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m----> 3\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_leaf_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'max_leaf_node'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10, max_leaf_nodes=50, n_estimators=100, random_state=42, verbose=2)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation using IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, accuracy_score, f1_score\n",
    "\n",
    "y_pred_whole = np.concatenate(y_pred)\n",
    "y_test_whole = np.concatenate(y_test)\n",
    "iou = jaccard_score(y_test_whole, y_pred_whole, average=None)\n",
    "print(f'IoU for each class: {iou}')\n",
    "print(f'Mean IoU: {np.mean(iou)}')\n",
    "print(f'Accuracy: {accuracy_score(y_test_whole, y_pred_whole)}')\n",
    "print(f'F1: {f1_score(y_test_whole, y_pred_whole, average=None)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.asarray(cv2.imread('V-01/image/1623379829-508641462.png'))\n",
    "img1 = cv2.resize(img1, target_size)\n",
    "features = extract_combined_features(img1)\n",
    "y_pred1 = rf.predict([features])\n",
    "\n",
    "img2 = np.asarray(cv2.imread('V-01/image/1623379830-781623853.png'))\n",
    "img2 = cv2.resize(img2, target_size)\n",
    "features = extract_combined_features(img2)\n",
    "y_pred2 = rf.predict([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = [[0, 0, 0], \n",
    "           [75, 25, 230], \n",
    "           [75, 180, 60], \n",
    "           [25, 225, 255], \n",
    "           [200, 130, 0], \n",
    "           [180, 30, 145], \n",
    "           [240, 240, 70], \n",
    "           [230, 50, 240], \n",
    "           [60, 245, 210], \n",
    "           [75, 25, 230], \n",
    "           [128, 128, 0], \n",
    "           [40, 110, 170], \n",
    "           [200, 250, 255], \n",
    "           [0, 0, 128], \n",
    "           [195, 255, 170], \n",
    "           [0, 128, 128], \n",
    "           [190, 190, 250], \n",
    "           [128, 0, 0], \n",
    "           [128, 128, 128]]\n",
    "\n",
    "\n",
    "y_pred1 = y_pred1.reshape(256,256)\n",
    "y_pred2 = y_pred2.reshape(256,256)\n",
    "\n",
    "result1 = np.array([[colours[num] for num in row] for row in y_pred1])\n",
    "actual1 = np.asarray(cv2.imread('V-01/label/1623379829-508641462.png'))\n",
    "actual1 =  cv2.resize(actual1, target_size)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(result1.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(actual1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = np.array([[colours[num] for num in row] for row in y_pred2])\n",
    "actual2 = np.asarray(cv2.imread('V-01/label/1623379830-781623853.png'))\n",
    "actual2 =  cv2.resize(actual2, target_size)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(result2.astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(actual2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
